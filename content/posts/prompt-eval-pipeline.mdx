---
title: "搭建 Prompt 迭代流水线"
summary: "介绍如何构建覆盖收集、回放、度量的 Prompt 评估体系。"
date: "2024-07-10"
category: "Engineering"
tags:
  - Prompt
  - Evaluation
  - Tooling
featured: false
coverImage: "https://images.unsplash.com/photo-1498050108023-c5249f4df085?auto=format&fit=crop&w=1600&q=80"
---

在团队中引入 AI 功能时，Prompt 的质量直接影响用户体验。为了形成持续迭代机制，我们需要一条可度量的流水线。

## 关键步骤

- **数据收集**：埋点记录用户输入与模型输出。
- **用例回放**：对关键场景进行定期回放，确保模型输出稳定。
- **指标体系**：结合自动评估与人工评审，形成可对比的数据集。

## 工具组合

| 功能 | 推荐工具 |
| --- | --- |
| 数据追踪 | Langfuse / OpenTelemetry |
| Prompt 版本管理 | git + prompt 文件夹 |
| 自动评估 | OpenAI Evals / 自建打分模型 |

将这些环节串联在一起，才能让 Prompt 迭代从「经验驱动」转向「数据驱动」。

